import nltk
from nltk.tokenize import sent_tokenize, word_tokenize

# Install NLTK data (uncomment the following line if not already installed)
# nltk.download('punkt')

# Define input text
input_text = "NLTK is a powerful library for natural language processing. It provides easy-to-use interfaces to perform various NLP tasks."

# Tokenize the text into sentences
sentence_tokens = sent_tokenize(input_text)

# Tokenize the text into words
word_tokens = word_tokenize(input_text)

# Display the results
print("Original Text:")
print(input_text)

print("\nSentence Tokens:")
print(sentence_tokens)

print("\nWord Tokens:")
print(word_tokens)
